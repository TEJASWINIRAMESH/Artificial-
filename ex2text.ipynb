{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoizuSMiSVgi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN,Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # Number of words to consider as features\n",
        "maxlen = 300        # Cut texts after this number of words\n",
        "embedding_dim = 128"
      ],
      "metadata": {
        "id": "9MfDNAVhSxPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "id": "7A0WOPkcSt70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "jlQoCW_9SsUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=maxlen))\n",
        "model.add(SimpleRNN(units=64))  # SimpleRNN layer with 64 units\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "QmT-Px0nSqwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "u6EEFI68SnPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "fiZPoeCpSlfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "0Qvy5HBOSjzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(text, tokenizer, maxlen):\n",
        "    # Tokenize the text\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    # Pad the sequences\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "uVzNuWVOShYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "\n",
        "# Instantiate a tokenizer and fit on the training data\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts([reverse_word_index.get(i - 3, \"?\") for i in range(3, vocab_size + 3)])"
      ],
      "metadata": {
        "id": "h90JDTFBSeT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom input text\n",
        "custom_text = \"I did not enjoy the movie. It was boring and too long.The music is also bad\"\n",
        "\n",
        "# Preprocess the custom input\n",
        "custom_input = preprocess_input(custom_text, tokenizer, maxlen)\n",
        "\n",
        "# Predict the sentiment of the custom input\n",
        "prediction = model.predict(custom_input)\n",
        "print(f\"Predicted Sentiment: {'Positive' if prediction[0][0] > 0.7 else 'Negative'}\")"
      ],
      "metadata": {
        "id": "_Nd6HHkkSbcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}